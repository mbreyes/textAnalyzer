{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "O objetivo desse programa é procurar por disciplinas do catálogo da UFABC e identificar disciplinas similares.\n",
    "\n",
    "Escrito por: Marcelo Bussotti Reyes - CMCC - UFABC\n",
    "Setembro de 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import csv\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente obtitve o catálogo de disciplinas em formato excel, gentilmente fornecido pela Prof. Paula Tiba e sua equipe da Pró-Reitoria de Graduação. Exportei para formato csv, colocando como delimitador de campo \"tab\". O nome do arquivo é "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'catalogo16_17.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d953ab699389>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvetor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mcatalogo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Aqui juntamos o texto de todas as ementas e colocamos num único string, para saber todas as palavras usadas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'catalogo16_17.csv'"
     ]
    }
   ],
   "source": [
    "filename = 'catalogo16_17.csv'\n",
    "colSigla  = 0                     # coluna que contém as siglas das disciplinas\n",
    "colNome   = 1                     # coluna com o nome das disciplinas\n",
    "colEmenta = 4                     # coluna com as ementas\n",
    "colBibliB = 5                     # coluna bibliografia básica\n",
    "colBibliC = 6                     # coluna bibliografia complementar\n",
    "\n",
    "stopWords = ['a'   , 'e' , 'é', 'o' , 'as' , 'os' ,'ao','aos', \\\n",
    "             'da'  , 'de', 'do' , 'das', 'dos',            \\\n",
    "             'em'  , 'na', 'no' , 'nos',                   \\\n",
    "             'para','com', 'por', 'à'  , 'às' , 'sobre',   \\\n",
    "             'um'   ,'uma',  'como', 'entre', 'que', 'ou',  \\\n",
    "             '¿'    , ]\n",
    "\n",
    "ELIM_MOST_FREQ = 200               # além das palavras acima, esta opção permite \n",
    "                                   # eliminar palavras mais frequentes presentes nas ementas\n",
    "ELIM_MULT_OCORRENCIAS = bool(1)    # se True - elimina a contagem múltipla de palavras, contanto somente 1 ocorrência\n",
    "\n",
    "''' Para a identificação das disciplinas, compilamos todas as palavras de cada ementa e \n",
    "    colocamos em um dicionário onde a chave é a palavra e o valor é o número de ocorrências \n",
    "    da palavra na ementa.''' \n",
    "\n",
    "def sortFreqDict(freqdict):\n",
    "    aux = [(freqdict[key], key) for key in freqdict]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux\n",
    "\n",
    "# removendo as palavras muito frequentes como artigos e preposições \n",
    "# as stopWords foram definidas no início da rotina\n",
    "def removeStopWords(texto,stopWords):\n",
    "    for sw in stopWords:                           # Laço para cada stopWord\n",
    "        # Remove as stopWords uma a uma. Foram incluídos espaços para evitar \n",
    "        #remover partes das palavras\n",
    "        texto = texto.replace(' '+sw+' ',' ')\n",
    "        #texto = texto.replace(sw+' ',' ')      \n",
    "    return texto\n",
    "\n",
    "def limpaTexto(texto,stopWords):\n",
    "    #transformacao = str.maketrans('', '', string.punctuation) #creates a table for translation for all puntuation\n",
    "    spcs = len(string.punctuation)*' '                        # creates a string with same length of punctuation\n",
    "    transformacao = str.maketrans(string.punctuation,spcs)    # creates a map from punctuation to white spaces\n",
    "    texto = texto.translate(transformacao)                    # removes all the punctuation\n",
    "    texto = texto.lower()                                     # makes all words in lower case\n",
    "    texto = removeStopWords(texto,stopWords)                  # removes stop words defined at the beginning\n",
    "    texto = texto.replace('\\n',' ')                           # removes the newline marks\n",
    "    return texto\n",
    "\n",
    "def criaVetor(texto):\n",
    "    palavras = texto.split()                              # quebra a string em uma lista de palavras\n",
    "    contagemPalavras = []                                 # inicia lista de palavras\n",
    "    for w in palavras:                                    # loop para cada palavra\n",
    "        contagemPalavras.append(palavras.count(w))        # conta o número de vezes que cada palavra ocorre na lista\n",
    "                                                          # e acrescenta à lista contagemPalavras\n",
    "    vetor =  dict(zip(palavras, contagemPalavras))        # Cria dicionário com as palavras e as respectivas contagens\n",
    "    return vetor\n",
    "\n",
    "catalogo = list(csv.reader(open(filename, 'r'), delimiter='\\t'))\n",
    "\n",
    "# Aqui juntamos o texto de todas as ementas e colocamos num único string, para saber todas as palavras usadas\n",
    "todasEmentas=''\n",
    "len(catalogo)\n",
    "for k in range(1,len(catalogo)):\n",
    "        todasEmentas = todasEmentas + ' ' + catalogo[k][colEmenta] + ' ' + catalogo[k][colBibliB]\n",
    "#todasEmentas = todasEmentas.replace('\\n',' ')\n",
    "\n",
    "# removendo pontuações e stop-words\n",
    "todasEmentasLimpo = limpaTexto(todasEmentas,stopWords)\n",
    "print(todasEmentasLimpo[1:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Este passo pode ser bastante demorado\n",
    "\n",
    "Nesse ponto temos uma lista (palavras) e uma lista de quantas vezes cada palavra ocorre (contagemPalavras). Vamos agora criar um dicionário com esses pares, e ordená-lo da mais frequente para a menos frequente. \n",
    "\n",
    "!!!Bastante demorado!!!! \n",
    "pode levar até 5 minutos para rodar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allPairs  = criaVetor(todasEmentasLimpo)\n",
    "sortPairs = sortFreqDict(allPairs)                    # usa a função definida no início para ordenar em ordem decrescente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emptyPairs = {}                                       # inicia variável\n",
    "for aux in allPairs.keys():                          # loop para todas as palavras\n",
    "    emptyPairs[aux] = 0                              # cria um dicionário com todas as palavras, mas com contagem zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por curiosidade, vamos visualizar as palavras mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(ELIM_MOST_FREQ+1):\n",
    "    # just for visualization, let's see the mostr frequent words...\n",
    "    print(str(k+1) + \": \" + str(sortPairs[k][1]) + ' ==> '+ str(sortPairs[k][0]) + ' vezes')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(ELIM_MOST_FREQ):               # loop for the number of words to be eliminated\n",
    "    sortPairs.remove(sortPairs[0])            # elimina primeiro da lista e retorna o vetor \"truncado\"\n",
    "    if k%10==0:\n",
    "        print(k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(ELIM_MOST_FREQ):\n",
    "    # just for visualization, let's see the mostr frequent words...\n",
    "    print(str(k) + \": \" + str(sortPairs[k][1]) + ' ==> '+ str(sortPairs[k][0]) + ' vezes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando vetores para palavras frequentes. Aqui, me refiro a vetores, porque são espécies de histogramas indexados pela própria palavra. Python permite esse tipo de estrutura através do tipo \"dicionário\", ou dict. Assim, é criado um dicionário que contém cada palavra da ementa como chave e o número de ocorrências como entrada. Ex. se a palavra civilização occorre 3 vezes, teremos uma linha do dicionário que será V['civilização']=3, ou {'civilização':3}. As duas maneiras são idênticas para o Python.\n",
    "\n",
    "Uma vez criado o vetor de todas as palavras, de todas as ementas, criamos um vetor para cada disciplina, usando como base o vetor geral, de forma que o dicionário de todas as ementas são iguais no número de entradas e nas chaves, somente diferindo no número de ocorrência de cada palavra. \n",
    "\n",
    "Fazendo os vetores idênticos, podemos criar uma matriz \"empilhando\" os vetores somente do número de entradas. Com isso, criamos uma matriz onde cada linha é o vetor de cada ementa do catálogo. As entradas da matriz V[i,j] são o número de occorrências de palavra[j] na ementa[i], para j indo da primeira à última palavra de todo o catálogo e i indo de 1 até o número de disciplinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "V = np.zeros((len(catalogo), len(emptyPairs)),dtype=int)    # inicia o vetor com o tamanho adequado (número de ementas)\n",
    "l = len(emptyPairs)                                         # guarda o valor do número de palavras total do catálogo\n",
    "palavras = list()\n",
    "palavras.append('none')\n",
    "for k in range(1,len(catalogo)):                           # loop para cada disciplina do catálogo\n",
    "    start = time.time()\n",
    "    if k%10==0:\n",
    "        print(k)\n",
    "        \n",
    "    estaSigla  = catalogo[k][colSigla ]                     # guarda a sigla da disciplina como uma string\n",
    "    estaEmenta = catalogo[k][colEmenta] + ' ' + catalogo[k][colBibliB]\n",
    "    \n",
    "    \n",
    "    estaEmentaLimpa = limpaTexto(estaEmenta,stopWords)      # remove as palavras muito frequêntes como preposições, etc\n",
    "    \n",
    "        \n",
    "    \n",
    "    palavras.append(estaEmentaLimpa.split())                # cria lista com as palavras menos frequentes de cada ementa\n",
    "    \n",
    "    print('append '+str(time.time()-start),end=' ')\n",
    "    \n",
    "    \n",
    "    esteVetor = criaVetor(estaEmentaLimpa)                  # cria o vetor com a contagem das palavras para essa disc.\n",
    "    \n",
    "    print('criaVetor '+str(time.time()-start),end=' ')\n",
    "    \n",
    "    \n",
    "    if ELIM_MULT_OCORRENCIAS:\n",
    "        for p in esteVetor.keys():                          # elimina múltiplas contagens de uma mesma palavra\n",
    "            if esteVetor[p]>0:                              # deixando o vetor somente com entradas 0 ou 1\n",
    "                esteVetor[p]=1\n",
    "    print('ELIM_MUL '+str(time.time()-start),end=' ')\n",
    "    \n",
    "    vetorCompleto = emptyPairs.copy()                       # cria uma cópia do histograma de todo o catálogo\n",
    "    vetorCompleto.update(esteVetor)                         # joga as contagens das palavras dessa disciplina no \n",
    "                                                            # dicionário geral. Esse passo é necessário para deixar todos\n",
    "                                                            # os dicionários das disciplinas com o mesmo tamamho e na\n",
    "                                                            # ordem.\n",
    "    print('vertorCompleto '+str(time.time()-start),end=' ')\n",
    "    \n",
    "    \n",
    "    if len(vetorCompleto) != l:                             # Aqui é um pequeno bug. Quando uma ementa começa com uma\n",
    "                                                            # palavra frequente, o algoritmo náo consegue remover\n",
    "                                                            # então preciso fazer essa checagem para uniformizar os vetores\n",
    "        s1 = set(vetorCompleto.keys())                      # joga todas as palavras dessa disciplina em um conjunto (set)\n",
    "        s2 = set(allPairs.keys())                           # joga todas as palavras de todas as disciplinas em um set\n",
    "        s1.difference_update(s2)                            # identifica qual é a palavra diferente guarda em s1\n",
    "        \n",
    "        for aux in s1:                                     # for para todas essas palavras\n",
    "            del vetorCompleto[aux]                          # apaga as entradas do dicionário dessa disciplina \n",
    "    #print(vetorCompleto.values())\n",
    "    type(vetorCompleto)\n",
    "    \n",
    "    V[k][:] = np.fromiter(iter(vetorCompleto.values()),dtype=int) # finalmente cria o vetor para essa disciplina e guarda em uma\n",
    "                                                                  # linha da matriz\n",
    "    print('V[k][:] '+str(time.time()-start),end=' ')\n",
    "     \n",
    "    M = np.inner(V,V)           # multiplica a matriz V pela transposta (V'), de forma a obter\n",
    "                                # um produto escalar dos histogramas, que dão uma medida da \n",
    "                                # da sobreposição entre eles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse ponto, temos uma matriz simétrica M[i,j] onde cada entrada é o produto escalar entre a disciplina[i] e a displina[j]. Porém o produto escalar pode variar muito com o tamanho das ementas. Assim, uma medida melhor é dividir o produto escalar pela \"norma\" de cada disciplina comparada, ou seja, criar um coeficiente coef = M[i,j]/(M[i,i]*M[j,j]), de forma que o coef tenha um valor máximo de 1 (100%) quando as ementas forem idênticas, e zero quando não tiverem qualquer palavra em comum.\n",
    "\n",
    "#Ordenando por sobreposição\n",
    "Aqui é somente uma preciosidade de ordenar as disciplinas por sobreposição, das mais sobrepostas às menos sobrepostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(I,J) = M.nonzero()   # Busca por valores não nulos na matriz M e joga os índices em I e J\n",
    "\n",
    "aux = np.array([[I[k],J[k],float(M[I[k],J[k]]*M[I[k],J[k]])/float(M[I[k],I[k]]*M[J[k],J[k]])] for k in range(I.size) ])\n",
    "# Deixando o código abaixo, caso se queira ordenar pelo coeficiente 2 (coef2)\n",
    "#minimo = min(M[I[k],I[k]],M[J[k],J[k]])\n",
    "#coef2= float(M[I[k],J[k]])/float(minimo)\n",
    "#aux = np.array([[I[k],J[k],coef2] for k in range(I.size) ])\n",
    "\n",
    "aux = aux[aux[:,2].argsort(),]             # ordena o vetor\n",
    "aux = aux[::-1,]                           # coloca o vetor em ordem reversa (de maior sobreposição para menor)\n",
    "\n",
    "I = aux[0:,0].tolist()                     # converte os índices, agora ordenados para uma lista do python\n",
    "I = [int(i) for i in I]                    # converte a lista para uma lista de inteiros\n",
    "J = aux[0:,1].tolist()                     # converte os índicer, agora ordenados para uma lista do python\n",
    "J = [int(j) for j in J]                    # converte a lista para uma lista de inteiros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse ponto temos os índices I e J definem os índices das disciplinas que têm alguma sobreposição. As listas estão organizadas da maior sobre posição para a menor.\n",
    "\n",
    "# Gerando lista com ementas em ordem de semelhança\n",
    "* Observação:foram eliminadas as disciplinas que contém as palavras: estágio, trabalho, tcc etc (ver código abaixo). Isso é para eliminar as disciplinas como trabalho de graduação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(len(I)):                                # loop para cada disciplina\n",
    "\n",
    "    # --- Calculando o coeficiente de sobreposição ---\n",
    "    coef = float(M[I[k],J[k]]*M[I[k],J[k]])/float(M[I[k],I[k]]*M[J[k],J[k]])\n",
    "    minimo = min(M[I[k],I[k]],M[J[k],J[k]]);\n",
    "    coef2= float(M[I[k],J[k]])/float(minimo)\n",
    "    nome = catalogo[I[k]][colNome].lower().split()\n",
    "    \n",
    "    # --- separando as ementas em listas de palavras para comparação ---\n",
    "    ementaI = catalogo[I[k]][colEmenta].split()\n",
    "    ementaJ = catalogo[J[k]][colEmenta].split()\n",
    "    \n",
    "    # --- Visualisando as emenstas em ordem decrescente de similaridade ---\n",
    "    #     Note que usamos I[k]<J[k]-3 para remover as que estão menos de 3 \n",
    "    #     ementas de \"distância\" no catálogo, que normalmente são versões\n",
    "    #     da mesma disciplina '''\n",
    "    if 0.1 < coef < 2 and I[k] < J[k]-3 and 'graduação' not in set(nome) and  \\\n",
    "        'estágio' not in set(nome) and    'tcc'       not in set(nome): \n",
    "        \n",
    "        # --- Imprimindo os coeficientes na tela para informação ---\n",
    "        print('Sobreposição = ',int(round(coef*100)),'%\\t', 'Sobreposição 2 = ', int(round(coef2*100)),'%')\n",
    "        \n",
    "        # --- Encontrando e imprimindo as palavras que estão em ambas as ementas --- \n",
    "        print('Palavras em comum:')\n",
    "        palavrasComuns = set(palavras[I[k]]).intersection(set(palavras[J[k]]))  # encontra intersecção entre ementas\n",
    "        palavrasComuns = list(palavrasComuns)                                   # transforma em uma lista\n",
    "        \n",
    "        for i in range(len(palavrasComuns)):\n",
    "            print(palavrasComuns[i],end=' ')      # imprime palavras encontradas em ambas as disciplinas, na mesma linha\n",
    "            \n",
    "        # --- imprimindo as ementas na tela para comparação ---    \n",
    "        print('\\n')\n",
    "        print(catalogo[I[k]][0],'-', catalogo[I[k]][1], '  --- número', I[k], ' do catálogo')\n",
    "        print(catalogo[I[k]][colEmenta])\n",
    "        print(catalogo[I[k]][colBibliB])\n",
    "        \n",
    "        print('\\n')\n",
    "        print(catalogo[J[k]][0],'-', catalogo[J[k]][1], '  --- número', J[k], ' do catálogo')\n",
    "        print(catalogo[J[k]][colEmenta])\n",
    "        print(catalogo[J[k]][colBibliB])\n",
    "        \n",
    "        print('\\n','_________________________________________','\\n\\n') "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
