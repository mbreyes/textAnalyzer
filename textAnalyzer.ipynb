{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "O objetivo desse programa é procurar por disciplinas do catálogo da UFABC e identificar disciplinas similares.\n",
    "\n",
    "Escrito por: Marcelo Bussotti Reyes - CMCC - UFABC\n",
    "Setembro de 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import RSLPStemmer\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente obtitve o catálogo de disciplinas em formato excel, gentilmente fornecido pela Prof. Paula Tiba e sua equipe da Pró-Reitoria de Graduação. Exportei para formato csv, colocando como delimitador de campo \"tab\". O nome do arquivo é "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'catalogo16_17.csv'\n",
    "colSigla  = 0                     # coluna que contém as siglas das disciplinas\n",
    "colNome   = 1                     # coluna com o nome das disciplinas\n",
    "colEmenta = 4                     # coluna com as ementas\n",
    "colBibliB = 5                     # coluna bibliografia básica\n",
    "colBibliC = 6                     # coluna bibliografia complementar\n",
    "\n",
    "stopWords = ['a'   , 'e' , 'é', 'o' , 'as' , 'os' ,'ao','aos',      \\\n",
    "             'da'  , 'de', 'do' , 'das', 'dos',                     \\\n",
    "             'em'  , 'na', 'no' , 'nos', '–',                           \\\n",
    "             'para','com', 'por', 'à'  , 'às' , 'sobre',            \\\n",
    "             'um'   ,'uma',  'como', 'entre', 'que', 'ou',          \\\n",
    "             'seu', 'sua', 'seus', 'suas', '2ª', 'são', 'paulo','rio','janeiro','rj','sp',\\\n",
    "             '¿'    , 'ed', 'and', 'of','press', 'org','et','não',  \\\n",
    "             'b', 'c', 'd','f','g','h','i','j','k','l','m',         \\\n",
    "             'n', 'o', 'p', 'q','r','s','t','u','v','w','x','y','z',\\\n",
    "             '1','2','3','4','5','6','7','8','9','new','york','isbn']\n",
    "\n",
    "year = 1980\n",
    "while year < 2017:\n",
    "    stopWords.append(str(year))\n",
    "    year = year +1;\n",
    "\n",
    "\n",
    "ELIM_MOST_FREQ = 500              # além palavras acima, esta opção permite \n",
    "                                   # eliminar palavras mais frequentes presentes nas ementas\n",
    "ELIM_MULT_OCORRENCIAS = bool(1)    # se True - elimina a contagem múltipla de palavras, contanto somente 1 ocorrência\n",
    "\n",
    "''' Para a identificação das disciplinas, compilamos todas as palavras de cada ementa e \n",
    "    colocamos em um dicionário onde a chave é a palavra e o valor é o número de ocorrências \n",
    "    da palavra na ementa.''' \n",
    "\n",
    "def sortFreqDict(freqdict):\n",
    "    aux = [(freqdict[key], key) for key in freqdict]\n",
    "    aux.sort()\n",
    "    aux.reverse()\n",
    "    return aux\n",
    "\n",
    "# removendo as palavras muito frequentes como artigos e preposições \n",
    "# as stopWords foram definidas no início da rotina\n",
    "def removeStopWords(texto,stopWords):\n",
    "    for sw in stopWords:                           # Laço para cada stopWord\n",
    "        # Remove as stopWords uma a uma. Foram incluídos espaços para evitar \n",
    "        #remover partes das palavras\n",
    "        texto = texto.replace(' '+sw+' ',' ')\n",
    "        #texto = texto.replace(sw+' ',' ')      \n",
    "    return texto\n",
    "\n",
    "def limpaTexto(texto,stopWords):\n",
    "    #transformacao = str.maketrans('', '', string.punctuation) #creates a table for translation for all puntuation\n",
    "    spcs = len(string.punctuation)*' '                         # creates a string with same length of punctuation\n",
    "    transformacao = str.maketrans(string.punctuation,spcs)     # creates a map from punctuation to white spaces\n",
    "    texto = texto.translate(transformacao)                     # removes all the punctuation\n",
    "    texto = texto.lower()                                      # makes all words in lower case\n",
    "    texto = removeStopWords(texto,stopWords)                   # removes stop words defined at the beginning\n",
    "    texto = texto.replace('\\n',' ')                            # removes the newline marks\n",
    "    return texto\n",
    "\n",
    "def criaVetor(texto):\n",
    "    palavras = texto.split()                              # quebra a string em uma lista de palavras\n",
    "    contagemPalavras = []                                 # inicia lista de palavras\n",
    "    for w in palavras:                                    # loop para cada palavra\n",
    "        contagemPalavras.append(palavras.count(w))        # conta o número de vezes que cada palavra ocorre na lista\n",
    "                                                          # e acrescenta à lista contagemPalavras\n",
    "    vetor =  dict(zip(palavras, contagemPalavras))        # Cria dicionário com as palavras e as respectivas contagens\n",
    "    return vetor\n",
    "\n",
    "catalogo = list(csv.reader(open(filename, 'r'), delimiter='\\t'))\n",
    "catalogo = catalogo[1:][:]\n",
    "\n",
    "# Aqui juntamos o texto de todas as ementas e colocamos num único string, para saber todas as palavras usadas\n",
    "todasEmentas=''\n",
    "\n",
    "for k in range(len(catalogo)):\n",
    "        todasEmentas = todasEmentas + ' ' + catalogo[k][colEmenta] + ' ' + catalogo[k][colBibliB]\n",
    "#todasEmentas = todasEmentas.replace('\\n',' ')\n",
    "\n",
    "# removendo pontuações e stop-words\n",
    "todasEmentasLimpo = limpaTexto(todasEmentas,stopWords)\n",
    "#print(todasEmentasLimpo[1:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Este passo pode ser bastante demorado\n",
    "\n",
    "Nesse ponto temos uma lista (palavras) e uma lista de quantas vezes cada palavra ocorre (contagemPalavras). Vamos agora criar um dicionário com esses pares, e ordená-lo da mais frequente para a menos frequente. \n",
    "\n",
    "!!!Bastante demorado!!!! \n",
    "pode levar até 5 minutos para rodar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allPairs  = criaVetor(todasEmentasLimpo)\n",
    "sortPairs = sortFreqDict(allPairs)                    # usa a função definida no início para ordenar em ordem decrescente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emptyPairs = {}                                       # inicia variável\n",
    "for aux in allPairs.keys():                          # loop para todas as palavras\n",
    "    emptyPairs[aux] = 0                              # cria um dicionário com todas as palavras, mas com contagem zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por curiosidade, vamos visualizar as palavras mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: sistemas ==> 543 vezes\n",
      "2: editora ==> 429 vezes\n",
      "3: introdução ==> 372 vezes\n",
      "4: análise ==> 358 vezes\n",
      "5: desenvolvimento ==> 294 vezes\n",
      "6: edição ==> 293 vezes\n",
      "7: teoria ==> 282 vezes\n",
      "8: brasil ==> 282 vezes\n",
      "9: aplicações ==> 255 vezes\n",
      "10: fundamentos ==> 234 vezes\n",
      "11: the ==> 225 vezes\n",
      "12: energia ==> 221 vezes\n",
      "13: conceitos ==> 220 vezes\n",
      "14: engenharia ==> 218 vezes\n",
      "15: filosofia ==> 209 vezes\n",
      "16: ensino ==> 204 vezes\n",
      "17: políticas ==> 201 vezes\n",
      "18: to ==> 194 vezes\n",
      "19: projeto ==> 194 vezes\n",
      "20: trabalho ==> 193 vezes\n",
      "21: métodos ==> 191 vezes\n",
      "22: política ==> 188 vezes\n",
      "23: wiley ==> 186 vezes\n",
      "24: modelos ==> 185 vezes\n",
      "25: hall ==> 184 vezes\n",
      "26: princípios ==> 183 vezes\n",
      "27: técnicas ==> 182 vezes\n",
      "28: in ==> 182 vezes\n",
      "29: processos ==> 179 vezes\n",
      "30: porto ==> 174 vezes\n",
      "31: introduction ==> 172 vezes\n",
      "32: educação ==> 171 vezes\n",
      "33: curso ==> 171 vezes\n",
      "34: planejamento ==> 168 vezes\n",
      "35: ciência ==> 168 vezes\n",
      "36: economia ==> 165 vezes\n",
      "37: sistema ==> 160 vezes\n",
      "38: prentice ==> 160 vezes\n",
      "39: alegre ==> 159 vezes\n",
      "40: materiais ==> 158 vezes\n",
      "41: ltc ==> 153 vezes\n",
      "42: ambiental ==> 151 vezes\n",
      "43: física ==> 150 vezes\n",
      "44: controle ==> 149 vezes\n",
      "45: história ==> 148 vezes\n",
      "46: university ==> 144 vezes\n",
      "47: gestão ==> 142 vezes\n",
      "48: sociais ==> 141 vezes\n",
      "49: redes ==> 139 vezes\n",
      "50: hill ==> 137 vezes\n",
      "51: john ==> 136 vezes\n",
      "52: cambridge ==> 136 vezes\n",
      "53: produção ==> 132 vezes\n",
      "54: se ==> 131 vezes\n",
      "55: principais ==> 131 vezes\n",
      "56: equações ==> 130 vezes\n",
      "57: projetos ==> 129 vezes\n",
      "58: problemas ==> 124 vezes\n",
      "59: brasileira ==> 124 vezes\n",
      "60: matemática ==> 122 vezes\n",
      "61: funções ==> 121 vezes\n",
      "62: química ==> 117 vezes\n",
      "63: estado ==> 117 vezes\n",
      "64: avaliação ==> 116 vezes\n",
      "65: públicas ==> 115 vezes\n",
      "66: estudo ==> 115 vezes\n",
      "67: ciências ==> 115 vezes\n",
      "68: fontes ==> 114 vezes\n",
      "69: relações ==> 112 vezes\n",
      "70: al ==> 112 vezes\n",
      "71: theory ==> 111 vezes\n",
      "72: elsevier ==> 111 vezes\n",
      "73: disponível ==> 111 vezes\n",
      "74: mcgraw ==> 110 vezes\n",
      "75: usa ==> 109 vezes\n",
      "76: processo ==> 107 vezes\n",
      "77: formação ==> 107 vezes\n",
      "78: dados ==> 107 vezes\n",
      "79: social ==> 106 vezes\n",
      "80: tipos ==> 105 vezes\n",
      "81: brasília ==> 105 vezes\n",
      "82: pesquisa ==> 103 vezes\n",
      "83: mecânica ==> 103 vezes\n",
      "84: estrutura ==> 103 vezes\n",
      "85: an ==> 103 vezes\n",
      "86: método ==> 102 vezes\n",
      "87: disciplina ==> 102 vezes\n",
      "88: cultura ==> 102 vezes\n",
      "89: http ==> 101 vezes\n",
      "90: springer ==> 100 vezes\n",
      "91: propriedades ==> 99 vezes\n",
      "92: meio ==> 99 vezes\n",
      "93: aspectos ==> 98 vezes\n",
      "94: básicos ==> 97 vezes\n",
      "95: teorema ==> 96 vezes\n",
      "96: sociedade ==> 96 vezes\n",
      "97: conhecimento ==> 96 vezes\n",
      "98: for ==> 95 vezes\n",
      "99: engineering ==> 94 vezes\n",
      "100: bookman ==> 94 vezes\n",
      "101: biologia ==> 94 vezes\n",
      "102: edition ==> 93 vezes\n",
      "103: características ==> 93 vezes\n",
      "104: evolução ==> 91 vezes\n",
      "105: br ==> 91 vezes\n",
      "106: elementos ==> 89 vezes\n",
      "107: processamento ==> 88 vezes\n",
      "108: nas ==> 87 vezes\n",
      "109: systems ==> 86 vezes\n",
      "110: prática ==> 86 vezes\n",
      "111: integração ==> 86 vezes\n",
      "112: ambiente ==> 86 vezes\n",
      "113: modelo ==> 84 vezes\n",
      "114: vol ==> 83 vezes\n",
      "115: informação ==> 83 vezes\n",
      "116: internacional ==> 82 vezes\n",
      "117: analysis ==> 82 vezes\n",
      "118: econômica ==> 81 vezes\n",
      "119: segurança ==> 80 vezes\n",
      "120: pearson ==> 80 vezes\n",
      "121: lógica ==> 80 vezes\n",
      "122: estudos ==> 80 vezes\n",
      "123: tecnologias ==> 79 vezes\n",
      "124: sons ==> 79 vezes\n",
      "125: martins ==> 79 vezes\n",
      "126: linear ==> 79 vezes\n",
      "127: dinâmica ==> 79 vezes\n",
      "128: artmed ==> 79 vezes\n",
      "129: oxford ==> 78 vezes\n",
      "130: nacional ==> 78 vezes\n",
      "131: cálculo ==> 78 vezes\n",
      "132: atlas ==> 78 vezes\n",
      "133: comunicação ==> 77 vezes\n",
      "134: tempo ==> 76 vezes\n",
      "135: temas ==> 76 vezes\n",
      "136: modelagem ==> 76 vezes\n",
      "137: científica ==> 76 vezes\n",
      "138: pelo ==> 75 vezes\n",
      "139: noções ==> 75 vezes\n",
      "140: calor ==> 75 vezes\n",
      "141: tecnologia ==> 74 vezes\n",
      "142: moderna ==> 74 vezes\n",
      "143: lei ==> 74 vezes\n",
      "144: programação ==> 73 vezes\n",
      "145: linguagem ==> 73 vezes\n",
      "146: geral ==> 73 vezes\n",
      "147: digital ==> 73 vezes\n",
      "148: urbana ==> 72 vezes\n",
      "149: crc ==> 71 vezes\n",
      "150: vozes ==> 70 vezes\n",
      "151: design ==> 70 vezes\n",
      "152: administração ==> 70 vezes\n",
      "153: science ==> 69 vezes\n",
      "154: campus ==> 69 vezes\n",
      "155: áreas ==> 68 vezes\n",
      "156: wesley ==> 68 vezes\n",
      "157: internacionais ==> 68 vezes\n",
      "158: elétrica ==> 68 vezes\n",
      "159: ambientais ==> 68 vezes\n",
      "160: relação ==> 67 vezes\n",
      "161: coleção ==> 67 vezes\n",
      "162: addison ==> 67 vezes\n",
      "163: 2 ==> 67 vezes\n",
      "164: século ==> 66 vezes\n",
      "165: saúde ==> 66 vezes\n",
      "166: papel ==> 66 vezes\n",
      "167: natureza ==> 66 vezes\n",
      "168: fluxo ==> 66 vezes\n",
      "169: 2a ==> 66 vezes\n",
      "170: unesp ==> 65 vezes\n",
      "171: normas ==> 65 vezes\n",
      "172: terra ==> 64 vezes\n",
      "173: termodinâmica ==> 64 vezes\n",
      "174: espaço ==> 64 vezes\n",
      "175: campinas ==> 64 vezes\n",
      "176: sinais ==> 63 vezes\n",
      "177: práticas ==> 63 vezes\n",
      "178: organização ==> 63 vezes\n",
      "179: função ==> 63 vezes\n",
      "180: bibliografia ==> 63 vezes\n",
      "181: 978 ==> 63 vezes\n",
      "182: inovação ==> 62 vezes\n",
      "183: guanabara ==> 62 vezes\n",
      "184: estruturas ==> 62 vezes\n",
      "185: conceito ==> 62 vezes\n",
      "186: 1ª ==> 62 vezes\n",
      "187: transferência ==> 61 vezes\n",
      "188: petrópolis ==> 61 vezes\n",
      "189: materials ==> 61 vezes\n",
      "190: industrial ==> 61 vezes\n",
      "191: cultural ==> 61 vezes\n",
      "192: área ==> 60 vezes\n",
      "193: textos ==> 60 vezes\n",
      "194: pensamento ==> 60 vezes\n",
      "195: pdf ==> 60 vezes\n",
      "196: nova ==> 60 vezes\n",
      "197: campo ==> 60 vezes\n",
      "198: básica ==> 60 vezes\n",
      "199: definição ==> 59 vezes\n",
      "200: construção ==> 59 vezes\n",
      "201: variáveis ==> 58 vezes\n",
      "202: urbano ==> 58 vezes\n",
      "203: geração ==> 58 vezes\n",
      "204: elaboração ==> 58 vezes\n",
      "205: conforme ==> 58 vezes\n",
      "206: classificação ==> 58 vezes\n",
      "207: 3 ==> 58 vezes\n",
      "208: universidade ==> 57 vezes\n",
      "209: teorias ==> 57 vezes\n",
      "210: ser ==> 57 vezes\n",
      "211: mercado ==> 57 vezes\n",
      "212: edgard ==> 57 vezes\n",
      "213: caracterização ==> 57 vezes\n",
      "214: 3ª ==> 57 vezes\n",
      "215: 1a ==> 57 vezes\n",
      "216: www ==> 56 vezes\n",
      "217: principles ==> 56 vezes\n",
      "218: jr ==> 56 vezes\n",
      "219: diferentes ==> 56 vezes\n",
      "220: desempenho ==> 56 vezes\n",
      "221: pública ==> 55 vezes\n",
      "222: outros ==> 55 vezes\n",
      "223: learning ==> 55 vezes\n",
      "224: global ==> 55 vezes\n",
      "225: 2nd ==> 55 vezes\n",
      "226: qualidade ==> 54 vezes\n",
      "227: plano ==> 54 vezes\n",
      "228: movimento ==> 54 vezes\n",
      "229: graduação ==> 54 vezes\n",
      "230: equação ==> 54 vezes\n",
      "231: circuitos ==> 54 vezes\n",
      "232: applications ==> 54 vezes\n",
      "233: abordagem ==> 54 vezes\n",
      "234: vida ==> 53 vezes\n",
      "235: questões ==> 53 vezes\n",
      "236: orientador ==> 53 vezes\n",
      "237: ordem ==> 53 vezes\n",
      "238: lineares ==> 53 vezes\n",
      "239: carvalho ==> 53 vezes\n",
      "240: brasileiro ==> 53 vezes\n",
      "241: potência ==> 52 vezes\n",
      "242: nuclear ==> 52 vezes\n",
      "243: médio ==> 52 vezes\n",
      "244: molecular ==> 52 vezes\n",
      "245: london ==> 52 vezes\n",
      "246: conflitos ==> 52 vezes\n",
      "247: algoritmos ==> 52 vezes\n",
      "248: tratamento ==> 51 vezes\n",
      "249: tema ==> 51 vezes\n",
      "250: solar ==> 51 vezes\n",
      "251: rede ==> 51 vezes\n",
      "252: radiação ==> 51 vezes\n",
      "253: mundo ==> 51 vezes\n",
      "254: manual ==> 51 vezes\n",
      "255: estratégias ==> 51 vezes\n",
      "256: direito ==> 51 vezes\n",
      "257: uso ==> 50 vezes\n",
      "258: tradução ==> 50 vezes\n",
      "259: solução ==> 50 vezes\n",
      "260: physics ==> 50 vezes\n",
      "261: partir ==> 50 vezes\n",
      "262: distribuição ==> 50 vezes\n",
      "263: crítica ==> 50 vezes\n",
      "264: control ==> 50 vezes\n",
      "265: atividade ==> 50 vezes\n",
      "266: movimentos ==> 49 vezes\n",
      "267: metodologia ==> 49 vezes\n",
      "268: gerenciamento ==> 49 vezes\n",
      "269: culturais ==> 49 vezes\n",
      "270: aplicação ==> 49 vezes\n",
      "271: academic ==> 49 vezes\n",
      "272: instituições ==> 48 vezes\n",
      "273: fluidos ==> 48 vezes\n",
      "274: estabilidade ==> 48 vezes\n",
      "275: diferenciais ==> 48 vezes\n",
      "276: componentes ==> 48 vezes\n",
      "277: cidades ==> 48 vezes\n",
      "278: 0 ==> 48 vezes\n",
      "279: síntese ==> 47 vezes\n",
      "280: mecanismos ==> 47 vezes\n",
      "281: la ==> 47 vezes\n",
      "282: koogan ==> 47 vezes\n",
      "283: funcionamento ==> 47 vezes\n",
      "284: formas ==> 47 vezes\n",
      "285: tópicos ==> 46 vezes\n",
      "286: simulação ==> 46 vezes\n",
      "287: series ==> 46 vezes\n",
      "288: recursos ==> 46 vezes\n",
      "289: poder ==> 46 vezes\n",
      "290: perspectiva ==> 46 vezes\n",
      "291: parâmetros ==> 46 vezes\n",
      "292: operação ==> 46 vezes\n",
      "293: modern ==> 46 vezes\n",
      "294: lisboa ==> 46 vezes\n",
      "295: histórico ==> 46 vezes\n",
      "296: grupos ==> 46 vezes\n",
      "297: atuação ==> 46 vezes\n",
      "298: atividades ==> 46 vezes\n",
      "299: verlag ==> 45 vezes\n",
      "300: revisão ==> 45 vezes\n",
      "301: planos ==> 45 vezes\n",
      "302: longo ==> 45 vezes\n",
      "303: imagens ==> 45 vezes\n",
      "304: handbook ==> 45 vezes\n",
      "305: econômico ==> 45 vezes\n",
      "306: contemporânea ==> 45 vezes\n",
      "307: bases ==> 45 vezes\n",
      "308: água ==> 44 vezes\n",
      "309: unicamp ==> 44 vezes\n",
      "310: paz ==> 44 vezes\n",
      "311: ondas ==> 44 vezes\n",
      "312: naturais ==> 44 vezes\n",
      "313: máquinas ==> 44 vezes\n",
      "314: massa ==> 44 vezes\n",
      "315: josé ==> 44 vezes\n",
      "316: comportamento ==> 44 vezes\n",
      "317: arte ==> 44 vezes\n",
      "318: aprendizagem ==> 44 vezes\n",
      "319: ufabc ==> 43 vezes\n",
      "320: silva ==> 43 vezes\n",
      "321: representação ==> 43 vezes\n",
      "322: operações ==> 43 vezes\n",
      "323: ministério ==> 43 vezes\n",
      "324: fundamentais ==> 43 vezes\n",
      "325: fisiologia ==> 43 vezes\n",
      "326: desafios ==> 43 vezes\n",
      "327: acordo ==> 43 vezes\n",
      "328: ética ==> 42 vezes\n",
      "329: séries ==> 42 vezes\n",
      "330: software ==> 42 vezes\n",
      "331: serão ==> 42 vezes\n",
      "332: risco ==> 42 vezes\n",
      "333: polímeros ==> 42 vezes\n",
      "334: ii ==> 42 vezes\n",
      "335: fourier ==> 42 vezes\n",
      "336: crescimento ==> 42 vezes\n",
      "337: cengage ==> 42 vezes\n",
      "338: através ==> 42 vezes\n",
      "339: 3rd ==> 42 vezes\n",
      "340: território ==> 41 vezes\n",
      "341: santos ==> 41 vezes\n",
      "342: princípio ==> 41 vezes\n",
      "343: instrumentos ==> 41 vezes\n",
      "344: indicadores ==> 41 vezes\n",
      "345: humana ==> 41 vezes\n",
      "346: gov ==> 41 vezes\n",
      "347: fundamentals ==> 41 vezes\n",
      "348: fundamental ==> 41 vezes\n",
      "349: experimental ==> 41 vezes\n",
      "350: estatística ==> 41 vezes\n",
      "351: equipamentos ==> 41 vezes\n",
      "352: dispositivos ==> 41 vezes\n",
      "353: contexto ==> 41 vezes\n",
      "354: conclusão ==> 41 vezes\n",
      "355: apresentação ==> 41 vezes\n",
      "356: 4ª ==> 41 vezes\n",
      "357: robert ==> 40 vezes\n",
      "358: regional ==> 40 vezes\n",
      "359: questão ==> 40 vezes\n",
      "360: petróleo ==> 40 vezes\n",
      "361: fase ==> 40 vezes\n",
      "362: equilíbrio ==> 40 vezes\n",
      "363: definições ==> 40 vezes\n",
      "364: david ==> 40 vezes\n",
      "365: chemistry ==> 40 vezes\n",
      "366: carlos ==> 40 vezes\n",
      "367: américa ==> 40 vezes\n",
      "368: volume ==> 39 vezes\n",
      "369: trad ==> 39 vezes\n",
      "370: problema ==> 39 vezes\n",
      "371: organizações ==> 39 vezes\n",
      "372: matéria ==> 39 vezes\n",
      "373: humano ==> 39 vezes\n",
      "374: horizonte ==> 39 vezes\n",
      "375: estados ==> 39 vezes\n",
      "376: espaços ==> 39 vezes\n",
      "377: conservação ==> 39 vezes\n",
      "378: conjuntos ==> 39 vezes\n",
      "379: caso ==> 39 vezes\n",
      "380: belo ==> 39 vezes\n",
      "381: base ==> 39 vezes\n",
      "382: soluções ==> 38 vezes\n",
      "383: orgs ==> 38 vezes\n",
      "384: local ==> 38 vezes\n",
      "385: letras ==> 38 vezes\n",
      "386: indústria ==> 38 vezes\n",
      "387: condições ==> 38 vezes\n",
      "388: campos ==> 38 vezes\n",
      "389: sensores ==> 37 vezes\n",
      "390: natural ==> 37 vezes\n",
      "391: maria ==> 37 vezes\n",
      "392: limites ==> 37 vezes\n",
      "393: indicada ==> 37 vezes\n",
      "394: exemplos ==> 37 vezes\n",
      "395: conhecimentos ==> 37 vezes\n",
      "396: cidade ==> 37 vezes\n",
      "397: capital ==> 37 vezes\n",
      "398: blücher ==> 37 vezes\n",
      "399: aplicados ==> 37 vezes\n",
      "400: 10 ==> 37 vezes\n",
      "401: transformações ==> 36 vezes\n",
      "402: proteção ==> 36 vezes\n",
      "403: convergência ==> 36 vezes\n",
      "404: clássicos ==> 36 vezes\n",
      "405: biomateriais ==> 36 vezes\n",
      "406: bem ==> 36 vezes\n",
      "407: 85 ==> 36 vezes\n",
      "408: 5ª ==> 36 vezes\n",
      "409: 4a ==> 36 vezes\n",
      "410: valor ==> 35 vezes\n",
      "411: transporte ==> 35 vezes\n",
      "412: thomson ==> 35 vezes\n",
      "413: territorial ==> 35 vezes\n",
      "414: souza ==> 35 vezes\n",
      "415: serviços ==> 35 vezes\n",
      "416: saraiva ==> 35 vezes\n",
      "417: resíduos ==> 35 vezes\n",
      "418: reais ==> 35 vezes\n",
      "419: professor ==> 35 vezes\n",
      "420: processing ==> 35 vezes\n",
      "421: mudança ==> 35 vezes\n",
      "422: mechanics ==> 35 vezes\n",
      "423: interação ==> 35 vezes\n",
      "424: industriais ==> 35 vezes\n",
      "425: estratégia ==> 35 vezes\n",
      "426: efeitos ==> 35 vezes\n",
      "427: crise ==> 35 vezes\n",
      "428: biológicos ==> 35 vezes\n",
      "429: utilização ==> 34 vezes\n",
      "430: transformação ==> 34 vezes\n",
      "431: reações ==> 34 vezes\n",
      "432: raton ==> 34 vezes\n",
      "433: publications ==> 34 vezes\n",
      "434: php ==> 34 vezes\n",
      "435: perspectivas ==> 34 vezes\n",
      "436: medidas ==> 34 vezes\n",
      "437: forma ==> 34 vezes\n",
      "438: escoamento ==> 34 vezes\n",
      "439: digitais ==> 34 vezes\n",
      "440: ciclo ==> 34 vezes\n",
      "441: boca ==> 34 vezes\n",
      "442: blucher ==> 34 vezes\n",
      "443: ação ==> 34 vezes\n",
      "444: automação ==> 34 vezes\n",
      "445: rural ==> 33 vezes\n",
      "446: riscos ==> 33 vezes\n",
      "447: resposta ==> 33 vezes\n",
      "448: produto ==> 33 vezes\n",
      "449: probabilidade ==> 33 vezes\n",
      "450: padrões ==> 33 vezes\n",
      "451: medição ==> 33 vezes\n",
      "452: leis ==> 33 vezes\n",
      "453: index ==> 33 vezes\n",
      "454: gás ==> 33 vezes\n",
      "455: físico ==> 33 vezes\n",
      "456: elétricos ==> 33 vezes\n",
      "457: democracia ==> 33 vezes\n",
      "458: visão ==> 32 vezes\n",
      "459: testes ==> 32 vezes\n",
      "460: tecidos ==> 32 vezes\n",
      "461: sustentabilidade ==> 32 vezes\n",
      "462: regulamentação ==> 32 vezes\n",
      "463: números ==> 32 vezes\n",
      "464: impactos ==> 32 vezes\n",
      "465: fatores ==> 32 vezes\n",
      "466: edusp ==> 32 vezes\n",
      "467: diversidade ==> 32 vezes\n",
      "468: diferenças ==> 32 vezes\n",
      "469: celular ==> 32 vezes\n",
      "470: aula ==> 32 vezes\n",
      "471: álgebra ==> 31 vezes\n",
      "472: urbanização ==> 31 vezes\n",
      "473: pós ==> 31 vezes\n",
      "474: onda ==> 31 vezes\n",
      "475: oficina ==> 31 vezes\n",
      "476: novos ==> 31 vezes\n",
      "477: manutenção ==> 31 vezes\n",
      "478: luz ==> 31 vezes\n",
      "479: livraria ==> 31 vezes\n",
      "480: interciência ==> 31 vezes\n",
      "481: gerais ==> 31 vezes\n",
      "482: formulação ==> 31 vezes\n",
      "483: eletrônica ==> 31 vezes\n",
      "484: difusão ==> 31 vezes\n",
      "485: células ==> 31 vezes\n",
      "486: concepções ==> 31 vezes\n",
      "487: computer ==> 31 vezes\n",
      "488: cidadania ==> 31 vezes\n",
      "489: boston ==> 31 vezes\n",
      "490: xx ==> 30 vezes\n",
      "491: world ==> 30 vezes\n",
      "492: with ==> 30 vezes\n",
      "493: técnico ==> 30 vezes\n",
      "494: transmissão ==> 30 vezes\n",
      "495: tensão ==> 30 vezes\n",
      "496: tendências ==> 30 vezes\n",
      "497: sem ==> 30 vezes\n",
      "498: seleção ==> 30 vezes\n",
      "499: river ==> 30 vezes\n",
      "500: resolução ==> 30 vezes\n",
      "501: regulação ==> 30 vezes\n"
     ]
    }
   ],
   "source": [
    "for k in range(ELIM_MOST_FREQ+1):\n",
    "    # just for visualization, let's see the mostr frequent words...\n",
    "    print(str(k+1) + \": \" + str(sortPairs[k][1]) + ' ==> '+ str(sortPairs[k][0]) + ' vezes')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in range(ELIM_MOST_FREQ):               # loop for the number of words to be eliminated\n",
    "    sortPairs.remove(sortPairs[0])            # elimina primeiro da lista e retorna o vetor \"truncado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: regulação ==> 30 vezes\n",
      "1: programming ==> 30 vezes\n",
      "2: primeira ==> 30 vezes\n",
      "3: metodologias ==> 30 vezes\n",
      "4: memória ==> 30 vezes\n",
      "5: matriz ==> 30 vezes\n",
      "6: legislação ==> 30 vezes\n",
      "7: identidade ==> 30 vezes\n",
      "8: histórica ==> 30 vezes\n",
      "9: governo ==> 30 vezes\n",
      "10: ferramentas ==> 30 vezes\n",
      "11: específico ==> 30 vezes\n",
      "12: escola ==> 30 vezes\n",
      "13: ensaios ==> 30 vezes\n",
      "14: edu ==> 30 vezes\n",
      "15: decisão ==> 30 vezes\n",
      "16: cortez ==> 30 vezes\n",
      "17: computação ==> 30 vezes\n",
      "18: companhia ==> 30 vezes\n",
      "19: combustão ==> 30 vezes\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "    # just for visualization, let's see the mostr frequent words...\n",
    "    print(str(k) + \": \" + str(sortPairs[k][1]) + ' ==> '+ str(sortPairs[k][0]) + ' vezes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando vetores para palavras frequentes. Aqui, me refiro a vetores, porque são espécies de histogramas indexados pela própria palavra. Python permite esse tipo de estrutura através do tipo \"dicionário\", ou dict. Assim, é criado um dicionário que contém cada palavra da ementa como chave e o número de ocorrências como entrada. Ex. se a palavra civilização occorre 3 vezes, teremos uma linha do dicionário que será V['civilização']=3, ou {'civilização':3}. As duas maneiras são idênticas para o Python.\n",
    "\n",
    "Uma vez criado o vetor de todas as palavras, de todas as ementas, criamos um vetor para cada disciplina, usando como base o vetor geral, de forma que o dicionário de todas as ementas são iguais no número de entradas e nas chaves, somente diferindo no número de ocorrência de cada palavra. \n",
    "\n",
    "Fazendo os vetores idênticos, podemos criar uma matriz \"empilhando\" os vetores somente do número de entradas. Com isso, criamos uma matriz onde cada linha é o vetor de cada ementa do catálogo. As entradas da matriz V[i,j] são o número de occorrências de palavra[j] na ementa[i], para j indo da primeira à última palavra de todo o catálogo e i indo de 1 até o número de disciplinas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "V = np.zeros((len(catalogo), len(emptyPairs)),dtype=int)    # inicia o vetor com o tamanho adequado (número de ementas)\n",
    "l = len(emptyPairs)                                         # guarda o valor do número de palavras total do catálogo\n",
    "palavras = list()\n",
    "palavras.append('none')\n",
    "for k in range(len(catalogo)):                           # loop para cada disciplina do catálogo\n",
    "    estaSigla  = catalogo[k][colSigla ]                     # guarda a sigla da disciplina como uma string\n",
    "    estaEmenta = catalogo[k][colEmenta] + ' ' + catalogo[k][colBibliB]   \n",
    "    estaEmentaLimpa = limpaTexto(estaEmenta,stopWords)      # remove as palavras muito frequêntes como preposições, etc    \n",
    "    palavras.append(estaEmentaLimpa.split())                # cria lista com as palavras menos frequentes de cada ementa\n",
    "    esteVetor = criaVetor(estaEmentaLimpa)                  # cria o vetor com a contagem das palavras para essa disc.\n",
    "    if ELIM_MULT_OCORRENCIAS:\n",
    "        for p in esteVetor.keys():                          # elimina múltiplas contagens de uma mesma palavra\n",
    "            if esteVetor[p]>0:                              # deixando o vetor somente com entradas 0 ou 1\n",
    "                esteVetor[p]=1\n",
    "    vetorCompleto = emptyPairs.copy()                       # cria uma cópia do histograma de todo o catálogo\n",
    "    vetorCompleto.update(esteVetor)                         # joga as contagens das palavras dessa disciplina no \n",
    "                                                            # dicionário geral. Esse passo é necessário para deixar todos\n",
    "                                                            # os dicionários das disciplinas com o mesmo tamamho e na\n",
    "                                                            # ordem.\n",
    "    if len(vetorCompleto) != l:                             # Aqui é um pequeno bug. Quando uma ementa começa com uma\n",
    "                                                            # palavra frequente, o algoritmo náo consegue remover\n",
    "                                                            # então preciso fazer essa checagem para uniformizar os vetores\n",
    "        s1 = set(vetorCompleto.keys())                      # joga todas as palavras dessa disciplina em um conjunto (set)\n",
    "        s2 = set(allPairs.keys())                           # joga todas as palavras de todas as disciplinas em um set\n",
    "        s1.difference_update(s2)                            # identifica qual é a palavra diferente guarda em s1\n",
    "        for aux in s1:                                     # for para todas essas palavras\n",
    "            del vetorCompleto[aux]                          # apaga as entradas do dicionário dessa disciplina \n",
    "\n",
    "    type(vetorCompleto)\n",
    "    \n",
    "    V[k][:] = np.fromiter(iter(vetorCompleto.values()),dtype=int) # finalmente cria o vetor para essa disciplina e guarda em uma\n",
    "                                                                  # linha da matriz\n",
    "M = np.inner(V,V)       # multiplica a matriz V pela transposta (V'), de forma a obter\n",
    "                        # um produto escalar dos histogramas, que dão uma medida da \n",
    "                        # da sobreposição entre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   0  10   5   2   2   3   4   1   1   2   2   4   4   1]\n",
      " [  0 100   0   4   0   0   0   0   0   0   0   0   4   4   4]\n",
      " [ 10   0 100   0   0   0   2   2   2   0   0   2   0   0   0]\n",
      " [  5   4   0 100  15   6   5   8   1   1   0   4   4   4   5]\n",
      " [  2   0   0  15 100  18   4  15   2   2   4   4   4   2   2]\n",
      " [  2   0   0   6  18 100  10  15   2   0   0   4   2   0   6]\n",
      " [  3   0   2   5   4  10 100  50  15   1   0   0   9   4   1]\n",
      " [  4   0   2   8  15  15  50 100  10   2   0   0   6   4   0]\n",
      " [  1   0   2   1   2   2  15  10 100   0   0   0   2   2   0]\n",
      " [  1   0   0   1   2   0   1   2   0 100  16  11   2   2   3]\n",
      " [  2   0   0   0   4   0   0   0   0  16 100  41   9   0   0]\n",
      " [  2   0   2   4   4   4   0   0   0  11  41 100   6   0   6]\n",
      " [  4   4   0   4   4   2   9   6   2   2   9   6 100  52  13]\n",
      " [  4   4   0   4   2   0   4   4   2   2   0   0  52 100   8]\n",
      " [  1   4   0   5   2   6   1   0   0   3   0   6  13   8 100]]\n"
     ]
    }
   ],
   "source": [
    "#aux2 = np.zeros(M.shape[0])\n",
    "#for aux in range(M.shape[0]):\n",
    "#    aux2[aux] = np.sum(M[:,aux])\n",
    "#print(aux2)\n",
    "\n",
    "#condition = M>=0.8\n",
    "\n",
    "#nonzero(M>0.8)\n",
    "#import scipy.io as sio\n",
    "#sio.savemat('V.mat', {'vect':V})\n",
    "\n",
    "\n",
    "M2 = np.copy(M).astype(float)\n",
    "for i in range((M.shape[0])):\n",
    "    for j in range(i,(M.shape[1])):\n",
    "        #print(i,j,M[i,j],M[j,i],M[i,i],M[j,j])\n",
    "        M2[i,j] = float(M[i,j])/float(min(M[i,i],M[j,j]))\n",
    "        M2[j,i] = M2[i,j]\n",
    "\n",
    "#np.set_printoptions(precision=2,suppress=True)    \n",
    "print(int32(M2[:15,:15]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolução e Diversidade de Plantas I\n",
      "Biologia Vegetal\n",
      "Fundamentos de Sistemática Vegetal\n",
      "________________\n",
      "Bombas Hidráulicas\n",
      "Turbinas Hidráulicas\n",
      "Ventiladores Industriais\n",
      "________________\n",
      "Morfofisiologia Humana III\n",
      "Ensino de Morfofisiologia Humana\n",
      "Morfofisiologia Humana II\n",
      "________________\n",
      "Estágio Curricular em Engenharia Aeroespacial\n",
      "Estágio Curricular em Engenharia Ambiental e Urbana\n",
      "Estágio Curricular em Engenharia Biomédica\n",
      "Estágio Curricular em Engenharia de Energia\n",
      "Estágio Curricular em Engenharia de Gestão\n",
      "Estágio Curricular em Engenharia de Informação\n",
      "Estágio Curricular em Engenharia de Instrumentação, Automação e Robótica\n",
      "Estágio Curricular em Engenharia de Materiais\n",
      "________________\n",
      "Projeto de Graduação em Computação I\n",
      "Projeto de Graduação em Computação II\n",
      "Projeto de Graduação em Computação III\n",
      "Estágio Supervisionado em Computação\n",
      "Projeto Interdisciplinar\n",
      "________________\n",
      "Estágio Supervisionado em Neurociência I\n",
      "Estágio Supervisionado em Neurociência II\n",
      "Estágio Supervisionado em Neurociência III\n",
      "________________\n",
      "Fundamentos de Zoologia dos Invertebrados\n",
      "Zoologia de Invertebrados I\n",
      "Zoologia Geral dos Invertebrados\n",
      "________________\n",
      "Tópicos Especiais em Engenharia Ambiental e Urbana\n",
      "Tópicos Especiais em Planejamento Territorial\n",
      "Práticas Especiais do Planejamento Territorial\n",
      "________________\n",
      "TCC de Relações Internacionais I\n",
      "TCC de Relações Internacionais II\n",
      "Trabalho de Conclusão de Curso de Políticas Públicas I\n",
      "Trabalho de Conclusão de Curso em Biologia\n",
      "Trabalho de Conclusão de Curso de Políticas Públicas II\n",
      "Trabalho de Conclusão de Curso em Química\n",
      "Trabalho de Conclusão de Curso I\n",
      "Trabalho de Conclusão de Curso II\n",
      "Trabalho de Graduação I em Ciências Econômicas\n",
      "________________\n",
      "Temas da Filosofia Antiga\n",
      "Temas da Filosofia Contemporânea\n",
      "Temas da Filosofia Medieval\n",
      "Temas da Filosofia Moderna\n",
      "Temas de Lógica\n",
      "________________\n",
      "Trabalho de Conclusão de Curso em Matemática I\n",
      "Trabalho de Conclusão de Curso em Matemática II\n",
      "Trabalho de Conclusão de Curso em Matemática III\n",
      "________________\n",
      "Trabalho de Graduação I em Engenharia Aeroespacial\n",
      "Trabalho de Graduação I em Engenharia Ambiental e Urbana\n",
      "Trabalho de Graduação I em Engenharia Biomédica\n",
      "Trabalho de Graduação I em Engenharia de Energia\n",
      "Trabalho de Graduação I em Engenharia de Gestão\n",
      "Trabalho de Graduação I em Engenharia de Informação\n",
      "Trabalho de Graduação I em Engenharia de Instrumentação, Automação e Robótica\n",
      "Trabalho de Graduação I em Engenharia de Materiais\n",
      "Trabalho de Graduação II em Engenharia Aeroespacial\n",
      "Trabalho de Graduação II em Engenharia Ambiental e Urbana\n",
      "Trabalho de Graduação II em Engenharia Biomédica\n",
      "Trabalho de Graduação II em Engenharia de Energia\n",
      "Trabalho de Graduação II em Engenharia de Gestão\n",
      "Trabalho de Graduação II em Engenharia de Informação\n",
      "Trabalho de Graduação II em Engenharia de Instrumentação, Automação e Robótica\n",
      "Trabalho de Graduação II em Engenharia de Materiais\n",
      "Trabalho de Graduação III em Engenharia Aeroespacial\n",
      "Trabalho de Graduação III em Engenharia Ambiental e Urbana\n",
      "Trabalho de Graduação III em Engenharia Biomédica\n",
      "Trabalho de Graduação III em Engenharia de Energia\n",
      "Trabalho de Graduação III em Engenharia de Gestão\n",
      "Trabalho de Graduação III em Engenharia de Informação\n",
      "Trabalho de Graduação III em Engenharia de Instrumentação, Automação e Robótica\n",
      "Trabalho de Graduação III em Engenharia de Materiais\n",
      "________________\n",
      "Transferência de Calor Aplicada a Sistemas Aeroespaciais\n",
      "Transferência de Calor I\n",
      "Transferência de Calor II\n",
      "________________\n"
     ]
    }
   ],
   "source": [
    "thres = 0.70\n",
    "j=4;\n",
    "a = ['trabalho', 'graduação', 'estágio', 'seminários', 'temas']\n",
    "\n",
    "MaxIter = 50\n",
    "toBeTested = set(range(M2.shape[1]))                          # todas as disciplinas a serem testadas\n",
    "#print(toBeTested)\n",
    "allTested  = set()                                # set que guarda todas as disciplinas testadas para evitar fazer repetições\n",
    "allSimilares = []\n",
    "l=0       # starting from the first discipline\n",
    "while len(toBeTested)>0:\n",
    "    N = 0\n",
    "    similares, tested = set(),set()\n",
    "    while N < MaxIter and l not in tested:\n",
    "        ind1 = set(np.where(M2[:,l] >= thres)[0])\n",
    "        [similares.add(c) for c in ind1]\n",
    "        tested.add(l)\n",
    "        allTested.add(l)\n",
    "        if l in toBeTested:\n",
    "            toBeTested.remove(l)\n",
    "        if tested != similares:\n",
    "            #print(similares,tested)\n",
    "            l = list(similares.difference(tested))[0]\n",
    "        else:\n",
    "            #print('no more elements found')\n",
    "            break\n",
    "        N = N+1\n",
    "    \n",
    "    if len(similares)>2:\n",
    "        [print(catalogo[k][colNome]) for k in similares ]\n",
    "        print('________________')\n",
    "    l=toBeTested.pop()\n",
    "    allSimilares.append(list(similares))\n",
    "    #print(l)    \n",
    "#print(ind1, similares)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f3c8b6080d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mthetaMax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthetaMax\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mthetaMax\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pairs' is not defined"
     ]
    }
   ],
   "source": [
    "thetaMax = pairs.max() \n",
    "i = np.complex(0,1)\n",
    "for k in np.arange(1,pairs.shape[0]):\n",
    "        a = pairs[k,0]-thetaMax/2/np.pi; \n",
    "        b = pairs[k,1]-thetaMax/2/np.pi;\n",
    "        x=np.vstack([[np.real(np.exp(i*a)),np.imag(np.exp(i*a))],[np.real(np.exp(i*b)),np.imag(np.exp(i*b))]])\n",
    "        plt.plot(x[:,0],x[:,1],'ko-');\n",
    "pylab.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse ponto, temos uma matriz simétrica M[i,j] onde cada entrada é o produto escalar entre a disciplina[i] e a displina[j]. Porém o produto escalar pode variar muito com o tamanho das ementas. Assim, uma medida melhor é dividir o produto escalar pela \"norma\" de cada disciplina comparada, ou seja, criar um coeficiente coef = M[i,j]/(M[i,i]*M[j,j]), de forma que o coef tenha um valor máximo de 1 (100%) quando as ementas forem idênticas, e zero quando não tiverem qualquer palavra em comum.\n",
    "\n",
    "#Ordenando por sobreposição\n",
    "Aqui é somente uma preciosidade de ordenar as disciplinas por sobreposição, das mais sobrepostas às menos sobrepostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(I,J) = M.nonzero()   # Busca por valores não nulos na matriz M e joga os índices em I e J\n",
    "\n",
    "#aux = np.array([[I[k],J[k],float(M[I[k],J[k]]*M[I[k],J[k]])/float(M[I[k],I[k]]*M[J[k],J[k]])] for k in range(I.size) ])\n",
    "# Deixando o código abaixo, caso se queira ordenar pelo coeficiente 2 (coef2)\n",
    "aux = np.array([[I[k],J[k], float(M[I[k],J[k]])/float(min(M[I[k],I[k]],M[J[k],J[k]])) ] for k in range(I.size) ])\n",
    "\n",
    "aux = aux[aux[:,2].argsort(),]             # ordena o vetor\n",
    "aux = aux[::-1,]                           # coloca o vetor em ordem reversa (de maior sobreposição para menor)\n",
    "\n",
    "I = aux[0:,0].tolist()                     # converte os índices, agora ordenados para uma lista do python\n",
    "I = [int(i) for i in I]                    # converte a lista para uma lista de inteiros\n",
    "J = aux[0:,1].tolist()                     # converte os índicer, agora ordenados para uma lista do python\n",
    "J = [int(j) for j in J]                    # converte a lista para uma lista de inteiros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse ponto temos os índices I e J definem os índices das disciplinas que têm alguma sobreposição. As listas estão organizadas da maior sobre posição para a menor.\n",
    "\n",
    "# Gerando lista com ementas em ordem de semelhança\n",
    "* Observação:foram eliminadas as disciplinas que contém as palavras: estágio, trabalho, tcc etc (ver código abaixo). Isso é para eliminar as disciplinas como trabalho de graduação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sobreposição =  100 %\n",
      "Palavras em comum:\n",
      "\n",
      "\n",
      "ESZT020-17 - Práticas Especiais do Planejamento Territorial   --- número 797  do catálogo\n",
      "O curso terá o programa definido em função do andamento das pesquisas, projetos e conteúdos que estão sendo realizados no âmbito do Planejamento Territorial.\n",
      "Será estabelecida a partir da definição do programa em cada quadrimestre.\n",
      "\n",
      "\n",
      "ESZT018-17 - Tópicos Especiais em Planejamento Territorial   --- número 1084  do catálogo\n",
      "O curso terá o programa definido em função do andamento das pesquisas, projetos e conteúdos que estão sendo realizados no âmbito do Planejamento Territorial.\n",
      "Será estabelecida a partir da definição do programa em cada quadrimestre.\n",
      "\n",
      " _________________________________________ \n",
      "\n",
      "\n",
      "Sobreposição =  100 %\n",
      "Palavras em comum:\n",
      "\n",
      "\n",
      "NHZ1042-15 - Seminários em Biologia I   --- número 937  do catálogo\n",
      "Tem como objetivo discutir temas atuais e tendências em diversas especialidades da Biologia. Através de seminários discentes, palestras de docentes da universidade, bem como de pesquisadores externos, serão apresentadas diversas áreas de pesquisa, metodologias e respectivas aplicações no campo das ciências biológicas e biomédicas.\n",
      "Bibliografia a ser definida pelo docente responsável e discentes.\n",
      "\n",
      "\n",
      "NHZ1043-15 - Seminários em Biologia II   --- número 938  do catálogo\n",
      "Tem como objetivo discutir temas atuais e tendências em diversas especialidades da Biologia. Através de seminários discentes, palestras de docentes da universidade, bem como de pesquisadores externos, serão apresentadas diversas áreas de pesquisa, metodologias e respectivas aplicações no campo das ciências biológicas e biomédicas.\n",
      "Bibliografia a ser definida pelo docente responsável e discentes.\n",
      "\n",
      " _________________________________________ \n",
      "\n",
      "\n",
      "Sobreposição =  100 %\n",
      "Palavras em comum:\n",
      "guanabara filogenia sistemática koogan \n",
      "\n",
      "NHT1093-16 - Fundamentos de Zoologia dos Invertebrados   --- número 416  do catálogo\n",
      "Fundamentos de sistemática; Origem e filogenia de Metazoa e “Protozoa”. Aspectos da biologia, morfologia e sistemática dos grupos \"Porifera\", Cnidaria, Ctenophora, Lophotrocozoa (Mollusca, Platyhelminthes e Anellida), Ecdysozoa (Gnathifera e Panarthropoda), Deuterostomata (Echinodermata) e outros pequenos filos de invertebrados não cordados.\n",
      "BRUSCA, Richard C.; BRUSCA, Gary J. Invertebrados. 2 ed. Rio de Janeiro: Guanabara Koogan, 2007. 968 p.\n",
      "RIBEIRO-COSTA, Cibele S.; ROCHA, Rosana Moreira da. Invertebrados: manual de aulas práticas. 2 ed. Ribeirão Preto: Holos Editora, 2006. 271 p.\n",
      "RUPPERT, Edwards E.; FOX, Richard S.; BARNES, Robert D. Zoologia dos invertebrados: uma abordagem funcional-evolutiva. 7.ed. São Paulo: Roca, 2005. 1142 p.\n",
      "\n",
      "\n",
      "NHT1089-15 - Zoologia Geral dos Invertebrados   --- número 1164  do catálogo\n",
      "Fundamentos de sistemática; Origem e filogenia de Metazoa e “Protozoa”. Aspectos da biologia, morfologia e sistemática dos grupos \"Porifera\", Cnidaria, Ctenophora, Lophotrocozoa (Mollusca, Platyhelminthes e Anellida), Ecdysozoa (Gnathifera e Panarthropoda), Deuterostomata (Echinodermata) e outros pequenos filos de invertebrados não cordados.\n",
      "BRUSCA, Richard C.; BRUSCA, Gary J. Invertebrados. 2 ed. Rio de Janeiro: Guanabara Koogan, 2007. 968 p.\n",
      "RIBEIRO-COSTA, Cibele S.; ROCHA, Rosana Moreira da. Invertebrados: manual de aulas práticas. 2 ed. Ribeirão Preto: Holos Editora, 2006. 271 p.\n",
      "RUPPERT, Edwards E.; FOX, Richard S.; BARNES, Robert D. Zoologia dos invertebrados: uma abordagem funcional-evolutiva. 7.ed. São Paulo: Roca, 2005. 1142 p.\n",
      "\n",
      " _________________________________________ \n",
      "\n",
      "\n",
      "Sobreposição =  97 %\n",
      "Palavras em comum:\n",
      "\n",
      "\n",
      "NHT1088-15 - Ensino de Morfofisiologia Humana   --- número 285  do catálogo\n",
      "Estratégias de ensino de morfofisiologia humana abordando a anatomia macro e microscópica, noções de embriogênese, malformações e fisiologia dos sistemas locomotor, cardiovascular, respiratório, urinário, digestório, endócrino, sistema nervoso e reprodutor. Ensino da Fisiologia da reprodução e sua regulação hormonal.\n",
      "CURI, Rui; PROCÓPIO, Joaquim; FERNANDES, Luiz Claudio. Praticando Fisiologia. São Paulo: Ed. Manole, 2005. 468p. ISBN: 8520416217\n",
      "GUYTON, Arthur C.; HALL, John E.. Tratado de fisiologia médica. 11 ed. Rio de Janeiro: Elsevier, 2006. 1115 p.\n",
      "PUTZ, R; PABST, R. Sobotta: atlas da anatomia humana: cabeça, pescoço e extremidade superior. 22.ed. Rio de Janeiro: Guanabara Koogan, c2006. v. 1. 416 p.\n",
      "PUTZ, R; PABST, R. Sobotta: atlas da anatomia humana: tronco, vísceras e extremidade inferior. 22.ed. Rio de Janeiro: Guanabara Koogan, c2006. v. 2. 398 p.\n",
      "\n",
      "\n",
      "NHT1060-15 - Morfofisiologia Humana III   --- número 680  do catálogo\n",
      "Anatomia macroscópica e fisiologia dos sistemas digestório, endócrino e reprodutor. Fisiologia da reprodução e sua regulação hormonal.\n",
      "GUYTON, Arthur C.; HALL, John E.. Tratado de fisiologia médica. 11 ed. Rio de Janeiro: Elsevier, 2006. 1115 p.\n",
      "PUTZ, R; PABST, R. Sobotta: atlas da anatomia humana: cabeça, pescoço e extremidade superior. 22.ed. Rio de Janeiro: Guanabara Koogan, c2006. v. 1. 416 p.\n",
      "PUTZ, R; PABST, R. Sobotta: atlas da anatomia humana: tronco, vísceras e extremidade inferior. 22.ed. Rio de Janeiro: Guanabara Koogan, c2006. v. 2. 398 p.\n",
      "\n",
      " _________________________________________ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percMin = 0.95\n",
    "for k in range(len(I)):                                # loop para cada disciplina\n",
    "\n",
    "    # --- Calculando o coeficiente de sobreposição ---\n",
    "    coef = float(M[I[k],J[k]]*M[I[k],J[k]])/float(M[I[k],I[k]]*M[J[k],J[k]])\n",
    "    minimo = min(M[I[k],I[k]],M[J[k],J[k]]);\n",
    "    coef2= float(M[I[k],J[k]])/float(minimo)\n",
    "    nome = catalogo[I[k]][colNome].lower().split()\n",
    "    \n",
    "    # --- separando as ementas em listas de palavras para comparação ---\n",
    "    ementaI = catalogo[I[k]][colEmenta].split()\n",
    "    ementaJ = catalogo[J[k]][colEmenta].split()\n",
    "    \n",
    "    # --- Visualisando as emenstas em ordem decrescente de similaridade ---\n",
    "    #     Note que usamos I[k]<J[k]-3 para remover as que estão menos de 3 \n",
    "    #     ementas de \"distância\" no catálogo, que normalmente são versões\n",
    "    #     da mesma disciplina '''\n",
    "    if percMin < coef2 and I[k] < J[k] and 'graduação' not in set(nome) and  \\\n",
    "        'estágio' not in set(nome) and    'tcc'    not in set(nome) and  \\\n",
    "        len(set('trabalho de conclusão'.split()) & set(nome))!=3: \n",
    "        \n",
    "        # --- Imprimindo os coeficientes na tela para informação ---\n",
    "        #print('Sobreposição = ',int(round(coef*100)),'%\\t', 'Sobreposição 2 = ', int(round(coef2*100)),'%')\n",
    "        print('Sobreposição = ', int(round(coef2*100)),'%')\n",
    "        # --- Encontrando e imprimindo as palavras que estão em ambas as ementas --- \n",
    "        print('Palavras em comum:')\n",
    "        palavrasComuns = set(palavras[I[k]]).intersection(set(palavras[J[k]]))  # encontra intersecção entre ementas\n",
    "        palavrasComuns = list(palavrasComuns)                                   # transforma em uma lista\n",
    "        \n",
    "        for i in range(len(palavrasComuns)):\n",
    "            print(palavrasComuns[i],end=' ')      # imprime palavras encontradas em ambas as disciplinas, na mesma linha\n",
    "            \n",
    "        # --- imprimindo as ementas na tela para comparação ---    \n",
    "        print('\\n')\n",
    "        print(catalogo[I[k]][0],'-', catalogo[I[k]][1], '  --- número', I[k], ' do catálogo')\n",
    "        print(catalogo[I[k]][colEmenta])\n",
    "        print(catalogo[I[k]][colBibliB])\n",
    "        \n",
    "        print('\\n')\n",
    "        print(catalogo[J[k]][0],'-', catalogo[J[k]][1], '  --- número', J[k], ' do catálogo')\n",
    "        print(catalogo[J[k]][colEmenta])\n",
    "        print(catalogo[J[k]][colBibliB])\n",
    "        \n",
    "        print('\\n','_________________________________________','\\n\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aux[1,:]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
